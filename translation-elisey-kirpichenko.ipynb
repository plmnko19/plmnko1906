{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ae30f9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-27T18:45:03.592343Z",
     "iopub.status.busy": "2025-03-27T18:45:03.592137Z",
     "iopub.status.idle": "2025-03-27T18:45:04.300553Z",
     "shell.execute_reply": "2025-03-27T18:45:04.299608Z"
    },
    "papermill": {
     "duration": 0.714283,
     "end_time": "2025-03-27T18:45:04.302061",
     "exception": false,
     "start_time": "2025-03-27T18:45:03.587778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/machine-translation-ioai/train.csv\n",
      "/kaggle/input/machine-translation-ioai/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d78fa57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:45:04.309635Z",
     "iopub.status.busy": "2025-03-27T18:45:04.309281Z",
     "iopub.status.idle": "2025-03-27T18:45:08.761385Z",
     "shell.execute_reply": "2025-03-27T18:45:08.760532Z"
    },
    "papermill": {
     "duration": 4.457464,
     "end_time": "2025-03-27T18:45:08.763090",
     "exception": false,
     "start_time": "2025-03-27T18:45:04.305626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d23d21b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:45:08.770781Z",
     "iopub.status.busy": "2025-03-27T18:45:08.770381Z",
     "iopub.status.idle": "2025-03-27T18:45:08.791458Z",
     "shell.execute_reply": "2025-03-27T18:45:08.790642Z"
    },
    "papermill": {
     "duration": 0.026476,
     "end_time": "2025-03-27T18:45:08.793084",
     "exception": false,
     "start_time": "2025-03-27T18:45:08.766608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/machine-translation-ioai/train.csv\")\n",
    "\n",
    "all_chars = set()\n",
    "for date in train[\"data\"]:\n",
    "    all_chars.update(str(date))\n",
    "for date in train[\"label\"]:\n",
    "    all_chars.update(str(date))\n",
    "\n",
    "all_chars = sorted(all_chars)\n",
    "char_to_idx = {char: idx + 2 for idx, char in enumerate(all_chars)}\n",
    "char_to_idx[\"<PAD>\"] = 0 \n",
    "char_to_idx[\"<SOS>\"] = 1 \n",
    "char_to_idx[\"<EOS>\"] = len(char_to_idx) \n",
    "\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "\n",
    "input_vocab_size = len(char_to_idx)\n",
    "output_vocab_size = len(char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9820fbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:45:08.801402Z",
     "iopub.status.busy": "2025-03-27T18:45:08.801170Z",
     "iopub.status.idle": "2025-03-27T18:45:08.806296Z",
     "shell.execute_reply": "2025-03-27T18:45:08.805489Z"
    },
    "papermill": {
     "duration": 0.010098,
     "end_time": "2025-03-27T18:45:08.807660",
     "exception": false,
     "start_time": "2025-03-27T18:45:08.797562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def string_to_tensor(s, max_length, add_sos_eos=False):\n",
    "    tensor = torch.zeros(max_length, dtype=torch.long)\n",
    "    s = str(s)\n",
    "    if add_sos_eos:\n",
    "        tensor[0] = char_to_idx[\"<SOS>\"]\n",
    "        for i, char in enumerate(s):\n",
    "            tensor[i + 1] = char_to_idx.get(char, char_to_idx[\"<PAD>\"])\n",
    "        tensor[len(s) + 1] = char_to_idx[\"<EOS>\"]\n",
    "    else:\n",
    "        for i, char in enumerate(s):\n",
    "            tensor[i] = char_to_idx.get(char, char_to_idx[\"<PAD>\"])\n",
    "    return tensor\n",
    "\n",
    "max_input_length = max(len(str(date)) for date in train[\"data\"]) + 2  # +2 для SOS/EOS\n",
    "max_output_length = len(\"DD-MM-YYYY\") + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d8b406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:45:08.814343Z",
     "iopub.status.busy": "2025-03-27T18:45:08.814122Z",
     "iopub.status.idle": "2025-03-27T18:45:08.826715Z",
     "shell.execute_reply": "2025-03-27T18:45:08.826126Z"
    },
    "papermill": {
     "duration": 0.017219,
     "end_time": "2025-03-27T18:45:08.827949",
     "exception": false,
     "start_time": "2025-03-27T18:45:08.810730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/machine-translation-ioai/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c6868ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:45:08.834696Z",
     "iopub.status.busy": "2025-03-27T18:45:08.834440Z",
     "iopub.status.idle": "2025-03-27T18:45:08.839211Z",
     "shell.execute_reply": "2025-03-27T18:45:08.838402Z"
    },
    "papermill": {
     "duration": 0.009522,
     "end_time": "2025-03-27T18:45:08.840458",
     "exception": false,
     "start_time": "2025-03-27T18:45:08.830936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DateDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        raw_date = self.df.iloc[idx][\"data\"]\n",
    "        target_date = self.df.iloc[idx][\"label\"]\n",
    "        \n",
    "        input_tensor = string_to_tensor(raw_date, max_input_length)\n",
    "        target_tensor = string_to_tensor(target_date, max_output_length, add_sos_eos=True)\n",
    "        \n",
    "        return input_tensor, target_tensor\n",
    "\n",
    "train_dataset = DateDataset(train)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77b4d1f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:45:08.847152Z",
     "iopub.status.busy": "2025-03-27T18:45:08.846954Z",
     "iopub.status.idle": "2025-03-27T18:45:08.850987Z",
     "shell.execute_reply": "2025-03-27T18:45:08.850349Z"
    },
    "papermill": {
     "duration": 0.008655,
     "end_time": "2025-03-27T18:45:08.852132",
     "exception": false,
     "start_time": "2025-03-27T18:45:08.843477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return outputs, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a12b7a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:45:08.858700Z",
     "iopub.status.busy": "2025-03-27T18:45:08.858465Z",
     "iopub.status.idle": "2025-03-27T18:45:08.862724Z",
     "shell.execute_reply": "2025-03-27T18:45:08.862068Z"
    },
    "papermill": {
     "duration": 0.008786,
     "end_time": "2025-03-27T18:45:08.863871",
     "exception": false,
     "start_time": "2025-03-27T18:45:08.855085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, encoder_outputs.size(1), 1)\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = torch.softmax(self.v(energy).squeeze(2), dim=1)\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2c9fafe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:45:08.870390Z",
     "iopub.status.busy": "2025-03-27T18:45:08.870184Z",
     "iopub.status.idle": "2025-03-27T18:45:08.875119Z",
     "shell.execute_reply": "2025-03-27T18:45:08.874507Z"
    },
    "papermill": {
     "duration": 0.009437,
     "end_time": "2025-03-27T18:45:08.876235",
     "exception": false,
     "start_time": "2025-03-27T18:45:08.866798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, embedding_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.attention = Attention(hidden_size)\n",
    "        self.lstm = nn.LSTM(embedding_size + hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell, encoder_outputs):\n",
    "        x = x.unsqueeze(1)\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        attn_weights = self.attention(hidden[-1], encoder_outputs)\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n",
    "        \n",
    "        lstm_input = torch.cat((embedded, context), dim=2)\n",
    "        output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "        \n",
    "        prediction = self.fc(output.squeeze(1))\n",
    "        return prediction, hidden, cell, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8448c5ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:45:08.882912Z",
     "iopub.status.busy": "2025-03-27T18:45:08.882706Z",
     "iopub.status.idle": "2025-03-27T18:45:08.887383Z",
     "shell.execute_reply": "2025-03-27T18:45:08.886826Z"
    },
    "papermill": {
     "duration": 0.009174,
     "end_time": "2025-03-27T18:45:08.888428",
     "exception": false,
     "start_time": "2025-03-27T18:45:08.879254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        batch_size = target.size(0)\n",
    "        target_len = target.size(1)\n",
    "        target_vocab_size = self.decoder.fc.out_features\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(source.device)\n",
    "        encoder_outputs, hidden, cell = self.encoder(source)\n",
    "        \n",
    "        decoder_input = target[:, 0]  # Первый токен — <SOS>\n",
    "        \n",
    "        for t in range(1, target_len):\n",
    "            output, hidden, cell, _ = self.decoder(decoder_input, hidden, cell, encoder_outputs)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            decoder_input = target[:, t] if teacher_force else output.argmax(1)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc2401c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:45:08.894896Z",
     "iopub.status.busy": "2025-03-27T18:45:08.894671Z",
     "iopub.status.idle": "2025-03-27T18:45:12.948957Z",
     "shell.execute_reply": "2025-03-27T18:45:12.948006Z"
    },
    "papermill": {
     "duration": 4.059196,
     "end_time": "2025-03-27T18:45:12.950552",
     "exception": false,
     "start_time": "2025-03-27T18:45:08.891356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# embedding_size = 256\n",
    "# hidden_size = 512\n",
    "embedding_size = 512\n",
    "hidden_size = 1024\n",
    "num_layers = 1\n",
    "\n",
    "encoder = Encoder(input_vocab_size, embedding_size, hidden_size, num_layers).to(device)\n",
    "decoder = Decoder(output_vocab_size, embedding_size, hidden_size, num_layers).to(device)\n",
    "model = Seq2Seq(encoder, decoder).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2a3474a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:45:12.957811Z",
     "iopub.status.busy": "2025-03-27T18:45:12.957436Z",
     "iopub.status.idle": "2025-03-27T18:45:45.262695Z",
     "shell.execute_reply": "2025-03-27T18:45:45.261632Z"
    },
    "papermill": {
     "duration": 32.310213,
     "end_time": "2025-03-27T18:45:45.264136",
     "exception": false,
     "start_time": "2025-03-27T18:45:12.953923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14, Loss: 1.4509\n",
      "Epoch 2/14, Loss: 0.7705\n",
      "Epoch 3/14, Loss: 0.6599\n",
      "Epoch 4/14, Loss: 0.3983\n",
      "Epoch 5/14, Loss: 0.2021\n",
      "Epoch 6/14, Loss: 0.0697\n",
      "Epoch 7/14, Loss: 0.0298\n",
      "Epoch 8/14, Loss: 0.0111\n",
      "Epoch 9/14, Loss: 0.0046\n",
      "Epoch 10/14, Loss: 0.0028\n",
      "Epoch 11/14, Loss: 0.0013\n",
      "Epoch 12/14, Loss: 0.0008\n",
      "Epoch 13/14, Loss: 0.0006\n",
      "Epoch 14/14, Loss: 0.0005\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 14\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (input_batch, target_batch) in enumerate(train_loader):\n",
    "        input_batch = input_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_batch, target_batch)\n",
    "        \n",
    "        loss = criterion(\n",
    "            output[:, 1:].reshape(-1, output_vocab_size),\n",
    "            target_batch[:, 1:].reshape(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdb6bd64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:45:45.272522Z",
     "iopub.status.busy": "2025-03-27T18:45:45.272262Z",
     "iopub.status.idle": "2025-03-27T18:45:45.277322Z",
     "shell.execute_reply": "2025-03-27T18:45:45.276488Z"
    },
    "papermill": {
     "duration": 0.010528,
     "end_time": "2025-03-27T18:45:45.278644",
     "exception": false,
     "start_time": "2025-03-27T18:45:45.268116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, input_str, max_length=12):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = string_to_tensor(input_str, max_input_length).unsqueeze(0).to(device)\n",
    "        encoder_outputs, hidden, cell = model.encoder(input_tensor)\n",
    "        \n",
    "        decoder_input = torch.tensor([char_to_idx[\"<SOS>\"]]).to(device)\n",
    "        output_str = \"\"\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            output, hidden, cell, _ = model.decoder(decoder_input, hidden, cell, encoder_outputs)\n",
    "            pred_token = output.argmax(1).item()\n",
    "            \n",
    "            if pred_token == char_to_idx[\"<EOS>\"]:\n",
    "                break\n",
    "            \n",
    "            output_str += idx_to_char[pred_token]\n",
    "            decoder_input = torch.tensor([pred_token]).to(device)\n",
    "        \n",
    "        return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c766023",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:45:45.286691Z",
     "iopub.status.busy": "2025-03-27T18:45:45.286419Z",
     "iopub.status.idle": "2025-03-27T18:46:29.245105Z",
     "shell.execute_reply": "2025-03-27T18:46:29.244122Z"
    },
    "papermill": {
     "duration": 43.964103,
     "end_time": "2025-03-27T18:46:29.246339",
     "exception": false,
     "start_time": "2025-03-27T18:45:45.282236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4676/4676 [00:43<00:00, 106.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "preds = []\n",
    "for input_str in tqdm(test['data'].values):\n",
    "    preds.append(predict(model, input_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cb5f7ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:46:29.291516Z",
     "iopub.status.busy": "2025-03-27T18:46:29.291284Z",
     "iopub.status.idle": "2025-03-27T18:46:29.313101Z",
     "shell.execute_reply": "2025-03-27T18:46:29.312475Z"
    },
    "papermill": {
     "duration": 0.045198,
     "end_time": "2025-03-27T18:46:29.314359",
     "exception": false,
     "start_time": "2025-03-27T18:46:29.269161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['label'] = preds\n",
    "test = test.set_index('id')\n",
    "test[['label']].to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11495692,
     "sourceId": 96694,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 89.711787,
   "end_time": "2025-03-27T18:46:30.755861",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-27T18:45:01.044074",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
