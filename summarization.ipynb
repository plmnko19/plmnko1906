{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ws1FXPusI0Bh"
   },
   "source": [
    "# Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArO8b4cQImY2"
   },
   "source": [
    "Alice continues her journey and now she is in 2015. Now it has become easier, as you can use word2vec! This time Alice needs help to solve the problem of summarizing news texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MVKm9UMe7XQ"
   },
   "source": [
    "The task of summarization is to obtain a shorter text from the original text, which will contain all (or almost all) the information that was in the original text. Thus, from the text you need to obtain its summary in such a way as to lose as little information as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjvxmiYAe7XQ"
   },
   "source": [
    "Methods for solving this problem are usually divided into two categories:\n",
    "- Extractive Summarization $-$ algorithms based on identifying the most informative parts of the source text (sentences, paragraphs, etc.) and compiling a summary from them.\n",
    "- Abstractive Summarization $-$ algorithms that generate new text based on the source.\n",
    "\n",
    "We will work with Extractive Summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nw_H8eHYe7XQ"
   },
   "source": [
    "## 0. Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "1QtEzk0qe7XR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from scipy import sparse\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UO9i_hsle7XR"
   },
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryDe-hb-e7XR"
   },
   "source": [
    "We will use data from the CNN/DailyMail news corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PxRpTtI4e7XR"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './cnn_stories_short/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pOa572LMe7XR"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!wget https://www.dropbox.com/s/kofxrgod7kl720m/cnn_stories_short.zip\n",
    "!mkdir cnn_data\n",
    "!unzip cnn_stories_short.zip -d $DATA_DIR\n",
    "!rm -r ./cnn_stories_short/__MACOSX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zf5xfzHpe7XS"
   },
   "source": [
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2VYb528e7XS"
   },
   "source": [
    "The dataset consists of source texts and already written summaries for them. We will save original texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "J4vWoH6je7XS"
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "for filename in os.listdir(DATA_DIR):\n",
    "    with open(os.path.join(DATA_DIR,filename),'r') as input_file:\n",
    "        all_texts = input_file.read().split('@highlight')\n",
    "        texts.append(all_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCJpPwu7e7XS"
   },
   "source": [
    "#### We will need:\n",
    "* texts broken into sentences\n",
    "* sentences broken into tokens\n",
    "* texts, broken sentences that are broken into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "khBgQs8jhSpd",
    "outputId": "19bf61fa-8807-4b4e-a2da-adfe65b58dcc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/xbar19/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pF7-yhxZe7XS"
   },
   "outputs": [],
   "source": [
    "sent_tokenized_texts = [sent_tokenize(text) for text in texts]\n",
    "tokenized_sentences = [word_tokenize(sent) for text in texts for sent in sent_tokenize(text)]\n",
    "tokenized_texts = [[word_tokenize(sent) for sent in text] for text in sent_tokenized_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6YEJa8Je7XS"
   },
   "source": [
    "### Loading Word Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ijvn-De8e7XS"
   },
   "source": [
    "For the TextRank algorithm, we need to obtain a vector representation for each sentence in the text.\n",
    "\n",
    "We will use pre-trained Glove vectors. **GloVe** (Global Vectors for Word Representation) is an unsupervised learning algorithm for obtaining vector representations for words, developed by Stanford University. It leverages global word-word co-occurrence statistics from a corpus to create dense vector embeddings that capture semantic meanings. GloVe vectors enable improved performance in various natural language processing tasks by representing words in a continuous vector space, where similar words are located closer together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0KFmssIe7XS"
   },
   "source": [
    "Let's load models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ss4NBNf4BWXX"
   },
   "source": [
    "The downloaded archive contains a set of files with vectors of different lengths. Each file stores a word on each line, followed by a space, the values ​​of the vector representation of this word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "EIxU3lDte7XS"
   },
   "outputs": [],
   "source": [
    "word_embeddings = {}\n",
    "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        word_embeddings[word] = np.asarray(values[1:], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NM0K0SK7Brc5"
   },
   "source": [
    "We stored vectors to word_embeddings value. Thus, word_embeddings is a dictionary, where key is a word and value is a vector of this word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxVuWQpyCJ5E"
   },
   "source": [
    "## Task 1: Word2Vec text representation\n",
    "\n",
    "*   For each text obtaint it's vector representation by averaging word2vec representation of each word. Just sum it component by component and divide on number of words in sentence. If word embedding model do not contain word initialize it with zeros. Use word representations saved in word_embeddings values.\n",
    "*   Count cosine similarity between each sentences and obtain matrix of cosine similarity **G**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "wNGnN6UTe7XS"
   },
   "outputs": [],
   "source": [
    "# TODO complete transform function. You can add additional values in class constructor if neccesary.\n",
    "\n",
    "class TfidfEmbeddingVectorizer:\n",
    "\n",
    "    def __init__(self, embedding_model, dim=100):\n",
    "        self.embedding_model = embedding_model # word embedding model\n",
    "        self.dim = dim\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Take list of texts as input, returns np.array with vector representation of each text.\n",
    "        sentence_vectors = []\n",
    "        for sentence in X:\n",
    "            word_vectors = []\n",
    "            for word in sentence:\n",
    "                if word in self.embedding_model:\n",
    "                    word_vectors.append(self.embedding_model[word])\n",
    "                else:\n",
    "                    word_vectors.append(np.zeros(self.dim))\n",
    "            if len(word_vectors) > 0:\n",
    "                sentence_vectors.append(np.mean(word_vectors, axis=0))\n",
    "            else:\n",
    "                sentence_vectors.append(np.zeros(self.dim))\n",
    "        return np.array(sentence_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "ssKKoVgCe7XS"
   },
   "outputs": [],
   "source": [
    "sentence_vectorizer = TfidfEmbeddingVectorizer(word_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIcz-AJge7XS"
   },
   "source": [
    "### Building the Cosine Similarity Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBPW-s9Qe7XS"
   },
   "source": [
    "For the *TextRank* algorithm, we need to build a weighted graph from the text. The graph will be represented as a matrix of cosine similarity between sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt-LVd1je7XS"
   },
   "source": [
    "For example, let's build a graph in the form of a distance matrix for one of the texts.\n",
    "Let's choose one text and build a distance matrix for it. We'll use the cosine distance as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "ZGcPZ5OIe7XS"
   },
   "outputs": [],
   "source": [
    "TEXT_NUM = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "OMJlptQ-e7XS"
   },
   "outputs": [],
   "source": [
    "sentences = tokenized_texts[TEXT_NUM]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VO-WdWRIe7XS"
   },
   "source": [
    "Using the vectorizer, we will obtain vectors for all sentences of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "CtLXZkxKe7XS"
   },
   "outputs": [],
   "source": [
    "vectorized_sentences = sentence_vectorizer.transform(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R21iKMMNe7XS"
   },
   "source": [
    "Let's calculate the matrix with cosine distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "XXGTMo30e7XS"
   },
   "outputs": [],
   "source": [
    "## TODO calculate the matrix of cosine similarity and assign it to G value.\n",
    "\n",
    "def get_cosine_similarity_matrix(sentences):\n",
    "    similarity_matrix = cosine_similarity(sentences)\n",
    "    return similarity_matrix\n",
    "\n",
    "G = get_cosine_similarity_matrix(vectorized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ET-m3hqe7XS"
   },
   "source": [
    "## Extractive Summarization $-$ TextRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kp-VMj13e7XS"
   },
   "source": [
    "Now we will implement the text summarization method itself. It will be based on the *PageRank* algorithm.\n",
    "\n",
    "*PageRank* $-$ is a recursive algorithm that evaluates the importance of each node in the graph based on its connections with other nodes. Initially, the algorithm was used to evaluate the importance of Internet pages for search engines.\n",
    "\n",
    "The adaptation of this algorithm for text summarization is called *TextRank*.\n",
    "\n",
    "The algorithm sequentially goes through all the nodes in the graph and recalculates the PageRank values ​​for each of them using the formula below.\n",
    "\n",
    "This happens until the process stabilizes, that is, the *PageRank* values ​​for all nodes stop changing significantly with each new iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71IpX-eJe7XS"
   },
   "source": [
    "$$ G = (V,E) - граф $$\n",
    "$$$$\n",
    "$$ PageRank(v) = \\frac{(1-d)}{N} +  d \\sum_{u} \\frac {PageRank(u) * W_{(u, v)}} {C(u)}$$\n",
    "\n",
    "$$v\\ -\\ вершина\\ графа, v \\in V $$\n",
    "\n",
    "$$u\\ -\\ вершины\\ графа,\\ такие\\ что\\ (u,v) \\in E$$\n",
    "\n",
    "$$C(u) - количество \\ вершин, \\ таких \\ что (u,v) \\in E$$\n",
    "\n",
    "$$W_{(u, v)} - вес\\ ребра\\ (u, v) \\in E $$\n",
    "\n",
    "$$d = 0,85\\ -\\ коэффициент\\ затухания$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmy85qpwe7XT"
   },
   "source": [
    "Let's use NetworkX library to Page Rank algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_VO53fXXe7XT",
    "outputId": "8f5b1e2e-4a75-4b0f-a61a-8a23dd6ca557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in ./MLEnv/lib/python3.10/site-packages (3.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "D8etYKWUe7XT"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "nx_graph = nx.from_numpy_array(G)\n",
    "nx_scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "DHfzMgS4e7XT"
   },
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((nx_scores[i], s, i) for i,s in enumerate(sentences)), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Igrhq5s8e7XT"
   },
   "source": [
    "Let's output 5 sentences with the highest TextRank. This will be our final text summation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cAEpPUaRe7XT",
    "outputId": "811efc82-5269-4bad-ef8f-5d6f1dd0d495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the next 20 minutes , Tuominen and information security researcher Robert Lee gave me a tutorial on making my iPhone settings hacker-proof .\n",
      "For more tips , check out the video .\n",
      "( CNNMoney ) -- Here 's one way to make your iPhone hacker-proof : Ask hackers for advice .\n",
      "Others take a bit more work , such as using settings to limit ad tracking .\n",
      "Some of them are basic -- like changing your four character password to something more complex .\n"
     ]
    }
   ],
   "source": [
    "SUMMARY_LEN = 5\n",
    "\n",
    "for i in range(SUMMARY_LEN):\n",
    "    print(' '.join(ranked_sentences[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4fkiVnue7XT"
   },
   "source": [
    "Now let's combine everything into one summarize function, which will receive text divided into sentences as input and output 5 sentences with the highest *TextRank*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "czbHL1xQe7XT"
   },
   "outputs": [],
   "source": [
    "def summarize(sentences,summary_len=5):\n",
    "    vectorized_sentences = sentence_vectorizer.transform(sentences)\n",
    "    G = get_cosine_similarity_matrix(vectorized_sentences)\n",
    "    nx_graph = nx.from_numpy_array(G)\n",
    "    nx_scores = nx.pagerank(nx_graph)\n",
    "    ranked_sentences = sorted(((nx_scores[i],s,i) for i,s in enumerate(sentences)), reverse=True)\n",
    "    summary = []\n",
    "    for i in range(summary_len):\n",
    "        summary.append(' '.join(ranked_sentences[i][1]))\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x90bwnQJe7XT",
    "outputId": "4aef9a79-89b0-466b-ec90-9372e9f5bace"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['For the next 20 minutes , Tuominen and information security researcher Robert Lee gave me a tutorial on making my iPhone settings hacker-proof .',\n",
       " 'For more tips , check out the video .',\n",
       " \"( CNNMoney ) -- Here 's one way to make your iPhone hacker-proof : Ask hackers for advice .\",\n",
       " 'Others take a bit more work , such as using settings to limit ad tracking .',\n",
       " 'Some of them are basic -- like changing your four character password to something more complex .']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(tokenized_texts[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8OXOauTe7XT"
   },
   "source": [
    "Let's get summaries for all our texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103,
     "referenced_widgets": [
      "340867e4d484439f93b2b35eedb9180a",
      "ee9dc90877ae4b50b0f0ece0d139aba8",
      "4b788a514e954e1c874fc0da68b9a40a",
      "79f1356f3a4f49368afb2f55773ea3d6",
      "ef729559d6d048059c300ee62e2992f6",
      "b7b96bff8e734db4b91172321635461f",
      "ca5baabab9c64ae49f7d2617d2b26fcd",
      "170368bdde0543dfbb92b9479a299e9f",
      "0892a613d87e4b0a83d4aebb3fb4ca7d",
      "42358745ad5149bfa4a2fedbe9827496",
      "2e1f9f18f01e4b75879170264826f98e"
     ]
    },
    "id": "W6-QvjoPe7XT",
    "outputId": "e95191bd-d521-40fc-ded5-9b5fcca0dd88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45739/557689583.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  system_summaries = [summarize(text) for text in tqdm(tokenized_texts)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37855b6d50174079aad5135637aefaaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_summaries = [summarize(text) for text in tqdm(tokenized_texts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_c_0DtTW9tX"
   },
   "source": [
    "Let's look on the 10th sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "LQ5FFoIOW6Qp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another high-profile striker on the move Monday was Tottenham 's Robbie Keane , who has agreed a loan switch to London rivals West Ham until the end of this season .\n",
      "Villa allowed Irish midfielder Stephen Ireland to join Newcastle on loan for the rest of this season , almost six months after he arrived from Manchester City .\n",
      "( CNN ) -- Fernando Torres ' highly-anticipated switch to English champions Chelsea was completed just before Monday transfer window closed in a deal that his former team Liverpool said had broken the British record .\n",
      "Torres ' move followed the news that Liverpool had agreed a club-record fee for Newcastle 's England striker Andy Carroll , who handed in a transfer request in the afternoon after the 18-time English champions made an improved bid .\n",
      "Stoke also allowed former Chelsea and Barcelona striker Eidur Gudjohnsen to join English rivals Fulham on loan , with the Iceland international having failed to win a regular place since his pre-season move from Monaco .\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(system_summaries[10][:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDN4nVJYGu4i"
   },
   "source": [
    "## Task 2 IDF word2vec modification\n",
    "\n",
    "Modify your previous solution. For each text obtaint it's vector representation by averaging word2vec representation of each word multiplied by the IDF value of this word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "2cHehImhHF2r"
   },
   "outputs": [],
   "source": [
    " #TODO complete transform function. You can add additional values in class constructor if neccesary.\n",
    "\n",
    "\n",
    "class TfidfEmbeddingVectorizer:\n",
    "\n",
    "    def __init__(self, embedding_model, dim=100):\n",
    "        self.embedding_model = embedding_model\n",
    "        self.dim = dim\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.vocab = None\n",
    "        self.idf = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        # TF-IDF fitting\n",
    "        self.vectorizer.fit([' '.join(doc) for doc in X])\n",
    "        self.vocab = self.vectorizer.vocabulary_\n",
    "        self.idf = self.vectorizer.idf_\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Take list of texts as input, returns np.array with vector representation of each text.\n",
    "        sentence_vectors = []\n",
    "\n",
    "        for doc in X:\n",
    "            word_vectors = []\n",
    "            total_weight = 0.0\n",
    "\n",
    "            for word in doc:\n",
    "                if word in self.embedding_model:\n",
    "                    if word in self.vocab:\n",
    "                        word_id = self.vocab[word]\n",
    "                        idf_value = self.idf[word_id]\n",
    "                    else:\n",
    "                        idf_value = 1.0 \n",
    "\n",
    "                    word_vector = self.embedding_model[word] * idf_value\n",
    "                    word_vectors.append(word_vector)\n",
    "                    total_weight += idf_value\n",
    "                else:\n",
    "                    word_vectors.append(np.zeros(self.dim))\n",
    "\n",
    "            if len(word_vectors) > 0:\n",
    "                sentence_vector = np.sum(word_vectors, axis=0) / total_weight\n",
    "            else:\n",
    "                sentence_vector = np.zeros(self.dim)\n",
    "\n",
    "            sentence_vectors.append(sentence_vector)\n",
    "\n",
    "        return np.array(sentence_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "Upsu9v71azGa"
   },
   "outputs": [],
   "source": [
    "sentence_vectorizer = TfidfEmbeddingVectorizer(word_embeddings)\n",
    "sentence_vectorizer = sentence_vectorizer.fit(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "Qe3BCk5BHqE_"
   },
   "outputs": [],
   "source": [
    "## TODO copy your function for cosine similarity here\n",
    "\n",
    "def get_cosine_similarity_matrix(sentences):\n",
    "    similarity_matrix = cosine_similarity(sentences)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "VnT8wwh3HkHC"
   },
   "outputs": [],
   "source": [
    "def summarize(sentences,summary_len=5):\n",
    "    vectorized_sentences = sentence_vectorizer.transform(sentences)\n",
    "    G = get_cosine_similarity_matrix(vectorized_sentences)\n",
    "    nx_graph = nx.from_numpy_array(G)\n",
    "    nx_scores = nx.pagerank(nx_graph)\n",
    "    ranked_sentences = sorted(((nx_scores[i],s,i) for i,s in enumerate(sentences)), reverse=True)\n",
    "    summary = []\n",
    "    for i in range(summary_len):\n",
    "        summary.append(' '.join(ranked_sentences[i][1]))\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLjw16jUH1Q5"
   },
   "source": [
    " Summarize your texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "ztVXsYR-HzAx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45739/557689583.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  system_summaries = [summarize(text) for text in tqdm(tokenized_texts)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c5fd4ed7ee4c3c8c758e2bbbd015be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_summaries = [summarize(text) for text in tqdm(tokenized_texts)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBNC5pqTICgz"
   },
   "source": [
    "Print summary for 7-th sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "Kqz8SPF1H_n2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`` Any attempt to rescue the girls by force will end in a tragic result -- it could be Nigeria 's Beslan , '' he said , referring to the attempt to free hostages at a school in Russia in 2004 that left more than 300 dead , many of them children .\n",
      "Nor would Zenn be surprised if Shekau were under the influence of drugs when he recorded his video statement ; they have sometimes been found in Boko Haram camps by the Nigerian military .\n",
      "`` Boko Haram has likely split up or sold the girls into many small groups , '' and they can be used as human shields in the event of an attack , he said .\n",
      "Sani believes Boko Haram targeted the girls to force concessions from the Nigerian government -- beginning perhaps with the release of Boko Haram followers from prisons .\n",
      "In his video , Shekau said of the girls : `` We would also give their hands in marriage because they are our slaves . ''\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(system_summaries[7]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0892a613d87e4b0a83d4aebb3fb4ca7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "170368bdde0543dfbb92b9479a299e9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e1f9f18f01e4b75879170264826f98e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "340867e4d484439f93b2b35eedb9180a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee9dc90877ae4b50b0f0ece0d139aba8",
       "IPY_MODEL_4b788a514e954e1c874fc0da68b9a40a",
       "IPY_MODEL_79f1356f3a4f49368afb2f55773ea3d6"
      ],
      "layout": "IPY_MODEL_ef729559d6d048059c300ee62e2992f6"
     }
    },
    "42358745ad5149bfa4a2fedbe9827496": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b788a514e954e1c874fc0da68b9a40a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_170368bdde0543dfbb92b9479a299e9f",
      "max": 300,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0892a613d87e4b0a83d4aebb3fb4ca7d",
      "value": 300
     }
    },
    "79f1356f3a4f49368afb2f55773ea3d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42358745ad5149bfa4a2fedbe9827496",
      "placeholder": "​",
      "style": "IPY_MODEL_2e1f9f18f01e4b75879170264826f98e",
      "value": " 300/300 [00:07&lt;00:00, 62.18it/s]"
     }
    },
    "b7b96bff8e734db4b91172321635461f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca5baabab9c64ae49f7d2617d2b26fcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee9dc90877ae4b50b0f0ece0d139aba8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7b96bff8e734db4b91172321635461f",
      "placeholder": "​",
      "style": "IPY_MODEL_ca5baabab9c64ae49f7d2617d2b26fcd",
      "value": "100%"
     }
    },
    "ef729559d6d048059c300ee62e2992f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
